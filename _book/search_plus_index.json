{"./":{"url":"./","title":"Introduction","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 Bourbon的个人博客 关于我 学习清单 关于博客 Bourbon的个人博客 关于我 软件工程本科在读。 现居重庆。 热爱技术，思考和审视世界。 学习清单 Golang 底层原理，常用库 计算机网络 操作系统 数据库：Mysql，Redis Linux 分布式与微服务相关组件 设计模式 关于博客 本博客使用Gitbook开发， 用以记录学习中的收获，以及开发过程中的问题。同时希望分享给有需要的同学。 如有错误，希望联系改正。欢迎交流探讨。 如果本博客能够帮助到您，欢迎打赏。 Github：https://github.com/BourbonWang Email: 1141134779@qq.com Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-23 15:24:35 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"golang/slice.html":{"url":"golang/slice.html","title":"详解 go slice","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 详解 Go slice slice 的存储结构 创建，初始化 空 slice 和 nil slice 对数组进行切片 append() 扩容 copy () slice做函数参数 详解 Go slice 切片 slice 是golang的复合类型，是对数组的补充。数组的长度不可变，go 提供了 slice 作为“动态数组”使用。 slice 底层依赖于数组。且支持通过 append() 向slice中追加元素，长度不够时会动态扩展，通过再次slice切片，可以得到得到更小的slice结构，可以迭代、遍历等。 slice 的存储结构 slice的底层结构由3部分组成： pointer：指向底层数组某个元素的指针 Length：slice当前的长度。追加元素时，长度会扩展，最大扩展到Capacity Capacity：底层数组的长度。由于slice的存储依赖于底层数组，所以Capacity也表示了slice最大能扩展到的长度 以上每部分占用8字节，所以一个slice都是24字节。 因此可以知道 golang 创建slice的过程：先创建一个有特定长度和数据类型的底层数组，然后从这个底层数组中选取一部分元素，返回这些元素组成的集合，并将 slice 指向集合中的第一个元素。换句话说，slice自身维护了一个指针属性，指向它底层数组中的某些元素的集合。 a := make([]int,3,5) fmt.Println(a) //[0 0 0] fmt.Println(len(a)) // 3 fmt.Println(cap(a)) // 5 println(a) //[3/5]0xc000094030 上面建立了一个长度为3的切片，它的底层数组长度为5。通过println()可以看出slice的结构，[3/5]表示length 和 capacity， 0xc000094030 表示指向底层数组的指针。这个slice的存储示意图： |---------|----------|--------| | pointer | capacity | length | slice：指向底层数组的第0个元素，长度为3 | | 5 | 3 | |-|-------|----------|--------| \\|/ |-|-----------------| array:长度为5,初始值为0的数组 | 0 | 0 | 0 | 0 | 0 | |---|---|---|---|---| 创建，初始化 直接创建 a := []int{1, 2, 3} //创建len和cap都为3的slice，并赋值 b := []int{9: 3} //创建len和cap都为10的slice，并将index=9的元素赋值3 // [0 0 0 0 0 0 0 0 0 3] 使用make()。可以先为底层数组分配好内存，然后从这个底层数组中再额外生成一个slice并初始化。 slice := make([]int,5) // 创建一个len和cap都为5的slice slice := make([]int,3,5) // 创建一个len=3,cap=5的slice 空 slice 和 nil slice 当声明一个slice，但不做初始化的时候，这个slice就是一个nil slice。 var nil_slice []int nil slice表示它的指向底层数组的指针为nil。也因此，nil slice的长度和容量都为0。 empty slice表示长度为0，容量为0，但却有指向的底层数组，只不过暂时是长度为0的空数组。 empty_slice := make([]int,0) empty_slice := []int{} 无论是nil slice还是empty slice，都可以对它们进行操作，如append()、len()和cap()。 对数组进行切片 对数组切片即为将slice的指针指向该数组，并利用length截取数组某一部分。 numbers := [9]int{0, 1, 2, 3, 4, 5, 6, 7, 8} //len=9 cap=9 slice1 := numbers[1:4] //len=3 cap=8 [1 2 3] slice2 := numbers[4:] //len=5 cap=5 slice=[4 5 6 7 8] 可见，底层数组始终为numbers，cap为剩余可用的数组容量。由于slice的指针指向的数组下标不同，导致了各自可用的cap不同。 因此，对于底层数组容量为k的切片slice[i : j]来说，len = j - i，cap = k - i。 改变切片元素，底层数组同时改变。改变数组元素，与其关联的切片随之改变。 numbers[2] = 10 fmt.Println(slice1) // [1 10 3] slice2[3] = 10 fmt.Println(numbers) // [0 1 10 3 4 5 6 10 8] 当多个slice共享同一个底层数组时，如果修改了某个slice中的元素，实际上修改的是底层数组的值，其它与之关联的slice也会随之改变。当同一个底层数组有很多slice的时候，一切将变得混乱不堪，因为我们不可能记住谁在共享它。所以，需要一种特性，保证各个slice的底层数组互不影响，相关内容见下面的\"扩容\"。 append() 追加元素到slice末尾。len会增加。当追加元素后的slice仍然未达到cap时，append()新元素将赋值给底层数组。当达到cap时，扩容机制将创建新的底层数组。 append()也可以用来合并slice。append()最多允许两个参数，所以一次性只能合并两个slice。但可以将append()作为另一个append()的参数，从而实现多级合并。 s1 := []int{1, 2} s2 := []int{3, 4} s3 := append(s1, s2...) //len=4 cap=4 [1 2 3 4] s4 := append(append(s1, s3...), s2...) //len=8 cap=12 //slice=[1 2 1 2 3 4 3 4] 扩容 当新的len 等于cap时，继续追加元素将引发扩容机制，开辟新的底层数组，将原来的数据复制过去。旧的底层数组仍然会被旧slice引用，新slice和旧slice不再共享同一个底层数组。 扩容的容量将进行如下判断： 首先判断，如果新申请容量（cap）大于2倍的旧容量（old.cap），最终容量（newcap）就是新申请的容量（cap）。 否则判断，如果旧切片的长度小于1024，则最终容量(newcap)就是旧容量(old.cap)的两倍。 否则判断，如果旧切片长度大于等于1024，则最终容量（newcap）从旧容量（old.cap）开始循环增加原来的1/4，即旧容量的1.25倍、1.5倍、1.75倍……直到最终容量（newcap）大于等于新申请的容量(cap)。 如果最终容量计算值溢出，则最终容量就是新申请容量(cap)。 my_slice := []int{1, 2, 3, 4, 5} // 限定长度和容量，且让长度和容量相等 new_slice := my_slice[1:3:3] // len=2 cap=2 [2 3] // 扩容 app_slice := append(new_slice, 44) // len=3 cap=4 [2 3 44] 当限定了slice的长度和容量时，如果需要扩容，golang将生成新的底层数组，而不是对原来的数组进行扩展，因此此时的新元素不会改变原来底层数组的值。 这样就可以解决上面提到的问题，因为创建了新的底层数组，所以修改不同的slice，将不会互相影响。为了保证每次都是修改各自的底层数组，通常会切出仅一个长度、仅一个容量的新slice，这样只要对它进行任何一次扩容，就会生成一个新的底层数组，从而让每个slice的底层数组都独立。 copy () copy(dst, src) 可以将src slice拷贝到dst slice。src比dst长，就截断; src比dst短，则只拷贝src那部分。这里的长度指len而不是容量cap。 copy的返回值是拷贝成功的元素数量，所以也就是src slice或dst slice中最小的那个长度。 s1 := []int{3, 4, 5} s2 := make([]int, 2, 7) copy(s1, s2) //s2: len=2 cap=7 [3 4] slice做函数参数 前面说过，slice的数据结构类似于[3/5]0xc000094030，仍可以将slice看作一种指针。这个特性直接体现在函数参数传值上。 Go中函数的参数是按值传递的，所以调用函数时会复制一个参数的副本传递给函数。如果传递给函数的是slice，它将复制该slice副本给函数，这个副本仍然是[3/5]0xc42003df10，它仍然指向源slice的底层数组。 如果函数内部对slice进行了修改，有可能会直接影响函数外部的底层数组，从而影响其它slice。但并不总是如此，例如函数内部对slice进行扩容，扩容时生成了一个新的底层数组，函数后续的代码只对新的底层数组操作，这样就不会影响原始的底层数组。 package main import \"fmt\" func main() { s1 := make([]int, 3, 4) // [0 0 0] foo(s1) printSlice(s1) // len=3 cap=4 [10 10 10] } func foo(s []int) { for i, _ := range s { //修改slice的值，将改变底层数组 s[i] += 10 } s = append(s, 3) //扩容将创建新的底层数组 s = append(s, 4) // len=5 cap=8 [10 10 10 3 4] s[1] = 20 //此时不会改变底层数组 printSlice(s) // len=5 cap=8 [10 20 10 3 4] } func printSlice(x []int) { fmt.Printf(\"len=%d cap=%d slice=%v\\n\", len(x), cap(x), x) } Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-09 12:41:18 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"golang/list.html":{"url":"golang/list.html","title":"常用库 container/list","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 container/list 包学习笔记 函数和功能 节点 链表 使用 创建链表 操作 遍历链表 数据结构实现 节点 链表 插入 移除 移动 container/list 包学习笔记 golang 的链表list的使用和具体实现。list对存储的元素并没有类型限制，比较方便。实现方式值得学习借鉴。 函数和功能 首先列出节点和链表的成员函数和功能。 节点 Next() ：前趋指针 Prev() ：后趋指针 链表 Init() ：初始化链表 Len() ：链表长度 Front() ：返回第一个节点的指针 Back() ：返回最后一个节点的指针 Remove(e) ：删除节点e，返回e的值 PushFront(value) ：将value加入链表头部，返回该节点 PushBack(value) ：将value加入链表尾部，返回该节点 InsertBefore(value, e) ：将value插入节点e之前，返回该节点 InsertAfter(value, e) ：将value插入节点e之后，返回该节点 MoveToFront(e) ：将节点e移动到链表头部 MoveToBack(e) ：将节点e移动到链表尾部 MoveBefore(e, mark) ：将节点e移动到节点mark前面 MoveAfter(e, mark) ：将节点e移动到节点mark后面 PushBackList(list) ：将另一个链表list连接到本链表尾部 PushFrontList(list) ：将另一个链表list连接到本链表头部 使用 创建链表 //使用提供的New()进行初始化 l := list.New() //使用var关键字 var l list.List 操作 l := list.New() l.PushBack(1) // 1 e := l.PushBack(2) // 1,2 l.PushFront(3) // 3,1,2 e = l.InsertBefore(4,e) // 3,1,4,2 e = l.InsertAfter(5,e) // 3,1,4,5,2 l.MoveToBack(e) // 3,1,4,2,5 l2 := list.New() l2.PushBack(7) l2.PushBack(8) l2.PushBack(9) //l2: 7,8,9 l.PushBackList(l2) //l: 3,1,4,2,5,7,8,9 l.PushFrontList(l2) //l: 7,8,9,3,1,4,2,5,7,8,9 遍历链表 for e := l.Front(); e != nil; e = e.Next() { // do something with e.Value } 数据结构实现 golang 的 list 使用双向环形链表实现。用一个root节点同时表示头节点和尾节点，第一个元素root.next，最后一个元素root.prev。root本身不存储数据。 节点 首先看节点的数据结构，list存放节点属于的链表，用来检验操作的节点是否属于该链表，避免非法传参。value存储值，可以为任何类型。 type Element struct { next, prev *Element // The list to which this element belongs. list *List // The value stored with this element. Value interface{} } 成员函数有Next()和Prev(): func (e *Element) Next() *Element { if p := e.next; e.list != nil && p != &e.list.root { return p } return nil } 链表 type List struct { root Element len int } 元素的操作依靠root节点。除了root节点外，len存储节点个数，不包括root。 初始化 func (l *List) Init() *List { l.root.next = &l.root l.root.prev = &l.root l.len = 0 return l } // New returns an initialized list. func New() *List { return new(List).Init() } Front()和Back()可以看出root节点同时作为头节点和尾节点 func (l *List) Front() *Element { if l.len == 0 { return nil } return l.root.next } func (l *List) Back() *Element { if l.len == 0 { return nil } return l.root.prev } 插入 对于插入操作，首先实现了节点到节点的插入，然后在其上封装了value到节点的插入，可用于之后的各种插入操作。 func (l *List) insert(e, at *Element) *Element { e.prev = at e.next = at.next e.prev.next = e e.next.prev = e e.list = l l.len++ return e } func (l *List) insertValue(v interface{}, at *Element) *Element { return l.insert(&Element{Value: v}, at) } 所以可以容易得到PushFront()和PushBack()的实现 func (l *List) PushFront(v interface{}) *Element { l.lazyInit() return l.insertValue(v, &l.root) } func (l *List) PushBack(v interface{}) *Element { l.lazyInit() return l.insertValue(v, l.root.prev) } 注意这里使用了懒加载，在第一次使用到的时候再进行初始化 func (l *List) lazyInit() { if l.root.next == nil { l.Init() } } InsertBefore()和InsertAfter()同理，要记得检验节点是否属于该链表 func (l *List) InsertBefore(v interface{}, mark *Element) *Element { if mark.list != l { return nil } return l.insertValue(v, mark.prev) } PushBackList()和PushFrontList()是合并链表的操作。同样依赖于基本的插入操作。对传入的链表进行遍历，插入到对应的位置。 func (l *List) PushBackList(other *List) { l.lazyInit() for i, e := other.Len(), other.Front(); i > 0; i, e = i-1, e.Next() { l.insertValue(e.Value, l.root.prev) } } func (l *List) PushFrontList(other *List) { l.lazyInit() for i, e := other.Len(), other.Back(); i > 0; i, e = i-1, e.Prev() { l.insertValue(e.Value, &l.root) } } 移除 移除操作的基本操作remove()，双链表的移除，把没用的指针设为nil func (l *List) remove(e *Element) *Element { e.prev.next = e.next e.next.prev = e.prev e.next = nil // avoid memory leaks e.prev = nil // avoid memory leaks e.list = nil l.len-- return e } 然后封装得到Remove()，同样应当检查要删除的节点是否属于该链表 func (l *List) Remove(e *Element) interface{} { if e.list == l { l.remove(e) } return e.Value } 移动 实现节点到节点的移动 func (l *List) move(e, at *Element) *Element { if e == at { return e } e.prev.next = e.next e.next.prev = e.prev e.prev = at e.next = at.next e.prev.next = e e.next.prev = e return e } 然后基于这个可以实现各种移动操作 func (l *List) MoveToFront(e *Element) { if e.list != l || l.root.next == e { return } l.move(e, &l.root) } func (l *List) MoveToBack(e *Element) { if e.list != l || l.root.prev == e { return } l.move(e, l.root.prev) } func (l *List) MoveBefore(e, mark *Element) { if e.list != l || e == mark || mark.list != l { return } l.move(e, mark.prev) } func (l *List) MoveAfter(e, mark *Element) { if e.list != l || e == mark || mark.list != l { return } l.move(e, mark) } Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-07 11:06:30 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"golang/string.html":{"url":"golang/string.html","title":"go 字符串","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 Go 字符串 字符串 定义字符串 拼接字符串 类型转换 检查前缀或后缀 Go 字符串 字符串 Go的字符串是一个任意字节的常量序列。Go语言中字符串的字节使用UTF-8编码表示Unicode文本，因此Go语言字符串是变宽字符序列，每一个字符都用一个或者多个字符表示，这跟其他的（C++，Java，Python 3）的字符串类型有着本质上的不同，后者为定宽字符序列。Go语言这样做不仅减少了内存和硬盘空间占用，同时也不用像其它语言那样需要对使用 UTF-8 字符集的文本进行编码和解码。 其他语言的字符串中的单个字符可以被字节索引，而Go中只有在字符串只包含7位的ASCII字符时才可以被字节索引。这并不代表Go在字符串处理能力上不足，因为Go语言支持一个字符一个字符的迭代，而且标准库中存在大量的字符串操作函数，最后我们还可以将Go语言的字符串转化为Unicode码点切片（类型为 [ ]rune），切片是支持直接索引的。 注：每一个Unicode字符都有一个唯一的叫做“码点”的标识数字。在Go语言中，一个单一的码点在内存中以 rune 的形式表示，rune表示int32类型的别名 定义字符串 字符串字面量使用双引号 \"\" 或者反引号 ` 来创建。 双引号用来创建可解析的字符串，支持转义，但不能用来引用多行； 反引号用来创建原生的字符串字面量，可能由多行组成，但不支持转义，并且可以包含除了反引号外其他所有字符。 s1 := \"Bourbon \\nBlog \\n\" s2 := `Bourbon\\n blog\\n ` fmt.Print(s1) fmt.Print(s2) 上面代码输出为： bourbon Blog Bourbon\\n blog\\n 可见，反引号定义的字符串不但保留了换行，还保留了缩进。 双引号创建可解析的字符串应用最广泛，反引号用来创建原生的字符串则多用于书写多行消息，HTML以及正则表达式。 拼接字符串 虽然Go中的字符串是不可变的，但是字符串支持 + 操作和+=操作 s1 := \"Bourbon\" s2 := \"blog\" s1 += \" \" + s2 fmt.Println(s1) // Bourbon blog 但这种方式在处理大量字符串连接的场景下将非常低效。使用 bytes.Buffer 连接字符串是一个更高效的方式，它会一次性将所有的内容连接起来转化成字符串。 var b bytes.Buffer for i := 0; i 下面比较两种拼接操作的性能差距 t := time.Now() var b bytes.Buffer for i := 0; i 可见，10000次的字符串拼接会导致数量级上的性能差距。 类型转换 在大多数语言中，可轻易地将任意数据类型转型为字符串。但在go中强制将整形转为字符串，你不会得到期望的结果。 i := 123 fmt.Println(string(i)) // { fmt.Println(strconv.Itoa(i)) // 123 string()会返回整型所对应的ASCII字符，想要正确将整型转换为字符串，应当使用strconv.Itoa() 。反之，将字符串转换为整型可以使用strconv.Atoi()。 另外还可以使用fmt.Sprintf函数将几乎所有数据类型转换为字符串，但通常应保留在这样的实例上，如正在创建的字符串包含嵌入数据，而非在期望将单个整数转换为字符串时用。 i := 123 s := fmt.Sprintf(\"the number is %d.\", i) fmt.Println(s) //the number is 123. 检查前缀或后缀 在处理字符串时，想要知道一个字符串是以一个特定的字符串开始还是以一个特定的字符串结束是非常常见的情况。可以使用strings.HasPrefix和strings.HasSuffix，它们将返回一个布尔值。 fmt.Println(strings.HasPrefix(\"something\", \"some\")) //true fmt.Println(strings.HasSuffix(\"something\", \"thing\")) //true Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-09 09:01:13 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"golang/mutex.html":{"url":"golang/mutex.html","title":"互斥锁 / 读写锁","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 互斥锁 Mutex 与 读写锁 RWMutex 互斥锁 Mutex 使用 状态 自旋 普通模式 / 饥饿模式 读写锁 RWMutex 原理 使用 互斥锁 Mutex 与 读写锁 RWMutex 互斥锁 在操作系统中，当多线程并发运行时，可能会访问或修改到共享的代码。比如下面这个例子，多个goroutine同时修改 n 的值： n := 0 add := func() { n = n + 1 } for i := 0; i 最终的输出很有可能不是100. 这是因为 n = n + 1在底层被解释为取值、加操作、赋值的3个操作。由于上下文切换，某个线程在执行这3个操作的过程中会被中断，另一个线程开始执行，从而导致了数据不一致。 这些共享资源的代码部分称为临界区（Critical Section）。应当保证临界区内代码的原子性。操作系统中使用信号量来保护临界区。对于上面这个例子，我们可以用二元信号量来保护临界区，即互斥锁。线程得到了资源，则对资源加锁，使用结束后释放锁。资源被加锁，其他线程将无法得到该资源，直到锁被释放。这样就保证了同时仅有1个线程正在访问资源。 Mutex 使用 Go 提供了 sync.Mutex来实现这个功能。Mutex只有两个方法：Lock() 和 Unlock()，分别代表了加锁和解锁。对于上面的例子，使用Mutex 来保护临界区： n := 0 mu := sync.Mutex{} add := func() { n = n + 1 } for i := 0; i 状态 查看源码，mutex的结构： type Mutex struct { state int32 sema uint32 } state 是状态码，包含了4项内容： Locked：表示是否上锁，上锁为1 未上锁为0 Woken：表示是否被唤醒，唤醒为1 未唤醒为0 Starving：表示是否为饥饿模式，饥饿模式为1 非饥饿模式为0 waiter：剩余的29位则为等待的goroutine数量 自旋 加锁时，如果当前Locked位为1，说明该锁当前由其他协程持有，尝试加锁的协程并不是马上转入阻塞，而是会持续的探测Locked位是否变为0，这个过程即为自旋过程。自旋时间很短（go设计为自旋4次），但如果在自旋过程中发现锁已被释放，那么协程可以立即获取锁。此时即便有协程被唤醒也无法获取锁，只能再次阻塞。 自旋的好处是，当加锁失败时不必立即转入阻塞，有一定机会获取到锁，这样可以避免协程的切换。 自旋的坏处是，如果自旋过程中获得锁，则马上执行该 goroutine。如果永远在自旋模式中，那么之前阻塞的goroutine 则很难获得锁，这样一来一些 goroutine 则会被阻塞时间过长。 普通模式 / 饥饿模式 go 对 mutex 的分配设计了两种模式。 在普通模式下，等待者以 FIFO 的顺序排队来获取锁，但被唤醒的等待者发现并没有获取到 mutex，并且还要与新到达的 goroutine 们竞争 mutex 的所有权。 在饥饿模式下，mutex 的所有权直接从对 mutex 执行解锁的 goroutine 传递给等待队列前面的等待者。新到达的 goroutine 们不要尝试去获取 mutex，即使它看起来是在解锁状态，也不要试图自旋。 读写锁 互斥锁的本质是当一个线程得到资源的时候，其他线程都不能访问。这样在资源同步，避免竞争的同时也降低了程序的并发性能。程序由原来的并行执行变成了串行执行。 其实，当我们对一个数据只做读操作的话，是不存在资源竞争的问题的。因为数据是不变的，不管多少个线程同时读取，都能得到同样的数据。所以问题不是出在读上，主要是写。要保证同时仅有一个线程在修改数据。所以真正的互斥应该是读和写、写和写之间，多个读者间没有互斥的必要。 因此，衍生出了读写锁。读写锁可以让多个读操作并发，但是对于写操作是完全互斥的。也就是说，当一个线程进行写操作的时候，其他线程既不能进行读操作，也不能进行写操作。 RWMutex 原理 操作系统中，可以使用信号量实现读写锁，也可以使用二元信号量即互斥锁实现。Go提供了读写锁sync.RWMutex，定义如下： type RWMutex struct { w Mutex // held if there are pending writers writerSem uint32 // 写锁需要等待读锁释放的信号量 readerSem uint32 // 读锁需要等待写锁释放的信号量 readerCount int32 // 读锁后面挂起了多少个写锁申请 readerWait int32 // 已释放了多少个读锁 } 可以看出RWMutex是基于Mutex实现的，在其基础上增加了读写的信号量。 读锁与读锁兼容，读锁与写锁互斥，写锁与写锁互斥，只有在锁释放后才可以继续申请互斥的锁： 可以同时申请多个读锁 有读锁时申请写锁将阻塞 只要有写锁，后续申请读锁和写锁都将阻塞 使用 提供了以下几个方法： //申请和释放写锁 func (rw *RWMutex) Lock() func (rw *RWMutex) Unlock() //申请和释放读锁 func (rw *RWMutex) RLock() func (rw *RWMutex) RUnlock() //返回一个实现Lock()和Unlock()的接口 func (rw *RWMutex) RLocker() Locker 如果不存在写锁，则Unlock()引发panic，如果不存在读锁，则RUnlock()引发panic 下面给出例子 package main import ( \"fmt\" \"sync\" \"time\" ) type data struct { N int RWM sync.RWMutex } func read(d *data, t time.Time) { d.RWM.RLock() time.Sleep(1 * time.Second) fmt.Printf(\"reader: n = %d, %s\\n\", d.N, time.Now().Sub(t).String()) d.RWM.RUnlock() } func write(d *data, t time.Time) { d.RWM.Lock() time.Sleep(3 * time.Second) d.N++ fmt.Printf(\"writer: n = %d, %s \\n\", d.N, time.Now().Sub(t).String()) d.RWM.Unlock() } func main() { t := time.Now() var d data for i := 0; i 创建了10个读线程，每个睡眠1秒；5个写线程，睡眠3秒。记录读者和写者的开始时间。输出如下： reader: n = 0, 1.000319542s reader: n = 0, 1.000435996s reader: n = 0, 1.000242171s reader: n = 0, 1.00048857s reader: n = 0, 1.000339988s reader: n = 0, 1.000224101s reader: n = 0, 1.000995623s writer: n = 1, 4.001359749s reader: n = 1, 5.001534292s reader: n = 1, 5.001578192s reader: n = 1, 5.001575223s writer: n = 2, 8.001839462s writer: n = 3, 11.00235864s writer: n = 4, 14.002692469s writer: n = 5, 17.002956352s 可以看出，由于可以同时读，多个读者间并没有发生阻塞。而写者由于锁机制，存在阻塞，延时3秒。 Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-13 13:48:52 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"golang/channel.html":{"url":"golang/channel.html","title":"详解 go channel","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 详解 Go channel channel 简介 channel 创建 channel 的类型 有缓存的 channel 无缓存的 channel nil channel channel 关闭 range select 使用规则 循环监听 超时处理 源码 类定义 make 实现 send 实现 recive 实现 close 实现 详解 Go channel channel 简介 Channel是Go中的一个核心类型，是 goroutine 之间通信的一种方式，可以类比成 Unix 中的进程的通信方式管道。在CSP模型中，并发执行实体对应goroutine，消息通道对应channel。channel 本身还需关联了一个类型，也就是 channel 可以发送数据的类型。例如: 发送 int 类型消息的 channel 写作 chan int 。 channel 创建 channel使用内置函数 make() 创建，其中包括了数据类型，以及容量capacity 。容量代表channel容纳的最多的元素的数量，代表channel的缓存的大小。如果没有设置容量，或者容量设置为0, 则创建的是无缓存channel。 ch := make(chan int, 100) channel和 slice，map 类似，make 创建了一个底层数据结构的引用，当赋值或参数传递时，只是拷贝了一个 channel 引用，指向相同的 channel 对象。和其他引用类型一样，channel 的空值为 nil 。使用 == 可以对类型相同的 channel 进行比较，只有指向相同对象或同为 nil 时，才返回 true. channel 的类型 有缓存的 channel 创建时指定了channel的容量，则为有缓存的channel。 类似一个阻塞队列（环形数组实现），当缓存未满时，向 channel 中发送消息时不会阻塞; 当缓存满时，发送操作将被阻塞，直到有其他 goroutine 从中读取消息； 相应的，当 channel 中消息不为空时，读取消息不会出现阻塞；当 channel 为空时，读取操作会造成阻塞，直到有 goroutine 向 channel 中写入消息。 通过 len 函数可以获得 chan 中的元素个数，通过 cap 函数可以得到 channel 的缓存长度。 无缓存的 channel 创建时未指定channel的容量，则为无缓存的channel。 从无缓存的 channel 中读取消息会阻塞，直到有 goroutine 向该 channel 中发送消息； 向无缓存的 channel 中发送消息也会阻塞，直到有 goroutine 从 channel 中读取消息。 func sum(s []int, c chan int) { sum := 0 for _, v := range s { sum += v } c 这个例子中，主线程x, y := 会一直被阻塞，直到有数据被发送到channel。从而实现了goroutine的同步。 nil channel 当未为channel分配内存时，channel就是nil channel。nil channel会永远阻塞对该channel的读、写操作。 var ch chan int // nil channel 因此，channel 一定要初始化后才能进行读写操作，否则会永久阻塞。 channel 关闭 golang 提供了内置的 close 函数对 channel 进行关闭操作。 ch := make(chan int) close(ch) 关闭一个nil channel 会产生 panic 重复关闭同一个 channel 会产生 panic 向一个已关闭的 channel 中发送消息会产生 panic 从已关闭的 channel 读取消息不会产生 panic，且能读出 channel 中还未被读取的消息。若消息均已读出，则会读到类型的零值。 从已关闭的 channel 中读取消息永远不会阻塞，并且会返回一个为 false 的 ok-idiom，可以用它来判断 channel 是否关闭 c := make(chan int, 10) close(c) i, ok := 关闭 channel 会产生一个广播机制，所有向 channel 读取消息的 goroutine 都会收到消息 range channel 也可以使用 range 遍历，并且会一直从 channel 中读取数据，直到有 goroutine 对改 channel 执行 close 操作，循环才会结束。如果没有goroutine 对channel 进行写操作，则会发生死锁。 func main() { ch := make(chan int, 10) ch 这个例子将输出 1 2 3，然后发生死锁，因为检测到不会再对channel进行写操作。 select 使用规则 select 可以同时监听多个 channel 的消息状态。类似于switch，但是只用于通信。 select { //do something case select 可以同时监听多个 channel 的写入或读取 执行 select 时，若只有一个 case 通过(不阻塞)，则执行这个 case 块 若有多个 case 通过，则随机挑选一个 case 执行 若所有 case 均阻塞，且定义了 default 模块，则执行 default 模块。若未定义 default 模块，则 select 语句阻塞，直到有 case 被唤醒。 nil channel上的操作会一直被阻塞，如果没有default case,只有nil channel的select会一直被阻塞。 使用 break 可以跳出 select 。 循环监听 select 和 switch 一样，它只会选择一个case来处理，如果想一直处理channel，可以在外面加一个无限的for循环，直到收到某信号后退出： for { select { case c 超时处理 因为上面我们提到，如果没有case需要处理，select语句就会一直阻塞着。这时候我们可能就需要一个超时操作，用来处理超时的情况。 func main() { c1 := make(chan string, 1) go func() { time.Sleep(time.Second * 2) c1 这个例子中，2秒后往 c1 中发送一个数据，但是 select 设置为1秒超时,因此我们会打印出timeout 1。它利用的是time.After方法，它返回一个类型为的单向的channel，在指定的时间发送一个当前时间给返回的channel中，被 select 接收，从而实现定时。 源码 $GOROOT/src/runtime/chan.go 类定义 type hchan struct { qcount uint // total data in the queue dataqsiz uint // size of the circular queue buf unsafe.Pointer // points to an array of dataqsiz elements elemsize uint16 closed uint32 elemtype *_type // element type sendx uint // send index recvx uint // receive index recvq waitq // list of recv waiters sendq waitq // list of send waiters // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. // // Do not change another G's status while holding this lock // (in particular, do not ready a G), as this can deadlock // with stack shrinking. lock mutex } type waitq struct { first *sudog last *sudog } make 实现 func makechan(t *chantype, size int) *hchan { elem := t.elem // compiler checks this but be safe. if elem.size >= 1 maxAlign { throw(\"makechan: bad alignment\") } mem, overflow := math.MulUintptr(elem.size, uintptr(size)) if overflow || mem > maxAlloc-hchanSize || size send 实现 // entry point for c 0 { t0 = cputicks() } lock(&c.lock) if c.closed != 0 { unlock(&c.lock) panic(plainError(\"send on closed channel\")) } if sg := c.recvq.dequeue(); sg != nil { // Found a waiting receiver. We pass the value we want to send // directly to the receiver, bypassing the channel buffer (if any). send(c, sg, ep, func() { unlock(&c.lock) }, 3) return true } if c.qcount 0 { blockevent(mysg.releasetime-t0, 2) } mysg.c = nil releaseSudog(mysg) return true } recive 实现 // entry points for 0 { t0 = cputicks() } lock(&c.lock) if c.closed != 0 && c.qcount == 0 { if raceenabled { raceacquire(c.raceaddr()) } unlock(&c.lock) if ep != nil { typedmemclr(c.elemtype, ep) } return true, false } if sg := c.sendq.dequeue(); sg != nil { // Found a waiting sender. If buffer is size 0, receive value // directly from sender. Otherwise, receive from head of queue // and add sender's value to the tail of the queue (both map to // the same buffer slot because the queue is full). recv(c, sg, ep, func() { unlock(&c.lock) }, 3) return true, true } if c.qcount > 0 { // Receive directly from queue qp := chanbuf(c, c.recvx) if raceenabled { raceacquire(qp) racerelease(qp) } if ep != nil { typedmemmove(c.elemtype, ep, qp) } typedmemclr(c.elemtype, qp) c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } c.qcount-- unlock(&c.lock) return true, true } if !block { unlock(&c.lock) return false, false } // no sender available: block on this channel. gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil gp.waiting = mysg mysg.g = gp mysg.isSelect = false mysg.c = c gp.param = nil c.recvq.enqueue(mysg) gopark(chanparkcommit, unsafe.Pointer(&c.lock), waitReasonChanReceive, traceEvGoBlockRecv, 2) // someone woke us up if mysg != gp.waiting { throw(\"G waiting list is corrupted\") } gp.waiting = nil gp.activeStackChans = false if mysg.releasetime > 0 { blockevent(mysg.releasetime-t0, 2) } closed := gp.param == nil gp.param = nil mysg.c = nil releaseSudog(mysg) return true, !closed } close 实现 func closechan(c *hchan) { if c == nil { panic(plainError(\"close of nil channel\")) } lock(&c.lock) if c.closed != 0 { unlock(&c.lock) panic(plainError(\"close of closed channel\")) } if raceenabled { callerpc := getcallerpc() racewritepc(c.raceaddr(), callerpc, funcPC(closechan)) racerelease(c.raceaddr()) } c.closed = 1 var glist gList // release all readers for { sg := c.recvq.dequeue() if sg == nil { break } if sg.elem != nil { typedmemclr(c.elemtype, sg.elem) sg.elem = nil } if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g gp.param = nil if raceenabled { raceacquireg(gp, c.raceaddr()) } glist.push(gp) } // release all writers (they will panic) for { sg := c.sendq.dequeue() if sg == nil { break } sg.elem = nil if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g gp.param = nil if raceenabled { raceacquireg(gp, c.raceaddr()) } glist.push(gp) } unlock(&c.lock) // Ready all Gs now that we've dropped the channel lock. for !glist.empty() { gp := glist.pop() gp.schedlink = 0 goready(gp, 3) } } Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-09 12:41:18 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"golang/json.html":{"url":"golang/json.html","title":"go 读写json文件","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 golang 读写 json 文件 将 struct 写入 json 文件 将 struct 转换成 json 将 json 写入文件 读取 json 文件转换 struct 读取json 文件 解析到结构体 golang 读写 json 文件 将 struct 写入 json 文件 定义一个结构体，注意成员名大写，否则 json 无法读取。 type Student struct { ID int Name string Scores []int } 将 struct 转换成 json tom := Student{ ID: 1, Name: \"Tom\", Scores: []int{99, 100, 80, 77}, } json, err := json.Marshal(tom) if err != nil { log.Fatal(err) } 将 json 写入文件 创建 test.json 文件，然后写入。 err = ioutil.WriteFile(\"test.json\", json, os.ModeAppend) if err != nil { log.Fatal(err) } test.json: {\"ID\":1,\"Name\":\"Tom\",\"Scores\":[99,100,80,77]} 读取 json 文件转换 struct 读取json 文件 stu := Student{} j, err := ioutil.ReadFile(\"test.json\") if err != nil { log.Fatal(err) } 解析到结构体 err = json.Unmarshal(j, &stu) if err != nil { log.Fatal(err) } fmt.Print(stu) // {1 Tom [99 100 80 77]} Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-10 12:28:07 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"network/https.html":{"url":"network/https.html","title":"HTTP 和 HTTPS","keywords":"","body":"HTTP 和 HTTPS Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-17 07:54:27 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"linux/chmod.html":{"url":"linux/chmod.html","title":".sh 添加执行权限","keywords":"","body":"给 .sh 文件添加执行权限 chmod u+x file.sh chmod (change the permissions mode of a file) 权限管理命令。 u代表所有者，x代表执行权限。 + 表示增加权限。 Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-08 05:47:49 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"other/git.html":{"url":"other/git.html","title":"Git同步本地项目到Github","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 Git同步本地项目到Github 本地git获取github提交权限 设置用户名和邮箱 生成ssh密钥 复制到github 测试完成 创建本地仓库 创建远程仓库 将本地仓库同步到远程仓库 添加远程仓库 将本地仓库的内容push到远程仓库的master分支 Git同步本地项目到Github 将本地的项目同步到github上，这样可以随时pull到本地，修改完后再push到github仓库。可以随时随地修改代码，也避免了项目的丢失的风险。 本地git获取github提交权限 设置用户名和邮箱 git config --global user.name 'your_name' git config --global user.email 'your_email' 生成ssh密钥 ssh-keygen -t rsa -C 'your_email' 提示设置存储位置和口令等，回车跳过。默认存储在 ~/.ssh/id_rsa.pub 复制到github 将生成的id_rsa.pub文件中的公钥复制到github的setting / SSH AND GPG KEY / SSH keys 测试完成 ssh git@github.com 提示 successfully authenticated 则成功。 创建本地仓库 cd到项目目录 git init 初始化git仓库 git add . 把所有项目文件添加到提交暂存区 git commit -m '提交说明' 把暂存区中的内容提交到仓库 创建远程仓库 github新建仓库，假设仓库名为[resName] 将本地仓库同步到远程仓库 添加远程仓库 git remote add origin git@github.com:[githubUerName]/[resName] 将本地仓库的内容push到远程仓库的master分支 git push -u origin master push的-u参数是设置本地仓库默认的upstream,这里就是把本地仓库同远程仓库的master分支进行关联，之后你在这个仓库pull时不带参数也默认从master分支拉取. Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-07 11:06:30 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"other/gitbook.html":{"url":"other/gitbook.html","title":"使用 Gitbook 搭建博客","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 使用 Gitbook 搭建博客 安装 node.js 编辑工具 Gitbook 初始化 目录 启动服务 插件 webhook 实现服务器自动更新博客 docker 部署 webhook 启动 webhook 配置 github 使用 Gitbook 搭建博客 gitbook 使用markdown 编写，简单易用。通过配置插件，也可以添加很多主题和小功能。适合搭建博客，电子书等。 安装 node.js gitbook是一个基于Node.js的命令行工具，所以要先安装Node.js(下载地址https://nodejs.org/en/，找到对应平台的版本安装即可)。 或使用包管理安装。 apt-get install nodejs 安装Gitbook： npm install -g gitbook-cli 编辑工具 typora：https://www.typora.io/ apt-get install typora Gitbook 初始化 在空文件夹中执行 gitbook init 文件夹中将多两个文件 README.md ：封面介绍 SUMMARY.md ：配置目录结构 目录 编辑SUMMARY.md # Summary * [Introduction](README.md) * [前言](readme.md) * [第一章](part1/README.md) * [第一节](part1/1.md) * [第二节](part1/2.md) * [第三节](part1/3.md) * [第四节](part1/4.md) * [第二章](part2/README.md) * [第三章](part3/README.md) * [第四章](part4/README.md) 编辑后执行 gitbook init 将自动按以上目录寻找或创建文件。 每一篇文章都是一个.md文件，这样就可以开始写博客了。 启动服务 编辑好文件后，执行 gitbook init gitbook serve gitbook将在本地4000端口启动服务。浏览器访问 http://localhost:4000/ 至此，已经可以使用 gitbook 搭建博客了。 插件 文件夹下创建 book.json ，如果已有，就直接打开。 配置插件等都是在这里，也可以复制别人的配置项。 plugins 是配置插件的位置，gitbook自带了5个插件，在名字前面加 - 可以禁用插件： sharing：右上角分享功能 font-settings：字体设置（左上方的\"A\"符号） livereload：为 GitBook 实时重新加载 highlight： 代码高亮 search： 导航栏查询功能（不支持中文） 推荐几个我在使用的插件： page-treeview：每篇文档头部生成标题树 code：为代码块添加行号和复制按钮 pageview-count：阅读量计数 popup：插件用于点击图片时，打开新的网页用来查看高清大图。 tbfed-pagefooter：在每个页面的最下方自动添加页脚信息 favicon：修改网页标题的图标 search-plus：原搜索插件不支持中文搜索，所以使用该插件进行替换。 expandable-chapters 和 chapter-fold ：导航目录 hide-element：隐藏界面元素 back-to-top-button：返回顶部按钮 splitter：侧边栏可自行调整宽度 sharing-plus：分享当前页面，比默认的 sharing 插件多了一些分享方式。 donate：打赏模块，在每篇文章底部都会加上一个按钮，点击显示图片 github：右上角跳转到 github 主页 附上我的配置文件 { \"author\": \"Bourbon\", \"description\": \"学习，记录，分享，进步\", \"extension\": null, \"generator\": \"site\", \"isbn\": \"\", \"links\": { \"sharing\": { \"all\": null, \"facebook\": null, \"google\": null, \"twitter\": null, \"weibo\": null } }, \"output\": null, \"pdf\": { \"fontSize\": 12, \"footerTemplate\": null, \"headerTemplate\": null, \"margin\": { \"bottom\": 36, \"left\": 62, \"right\": 62, \"top\": 36 }, \"pageNumbers\": true, \"paperSize\": \"a4\" }, \"plugins\": [ \"page-treeview\", \"code\", \"pageview-count\", \"popup\", \"tbfed-pagefooter\", \"favicon\", \"search-plus\", \"expandable-chapters\", \"hide-element\", \"back-to-top-button\", \"splitter\", \"-lunr\", \"-search\", \"-sharing\", \"sharing-plus\", \"chapter-fold\", \"donate\", \"github\" ], \"pluginsConfig\": { \"code\": { \"copyButtons\": false }, \"hide-element\": { \"elements\": [\".gitbook-link\"] }, \"tbfed-pagefooter\": { \"copyright\": \"Copyright © 1141134779@qq.com 2020\" }, \"favicon\": { \"shortcut\": \"assert/favicon.ico\", \"bookmark\": \"assert/favicon.ico\", \"appleTouch\": \"assert/favicon.ico\", \"appleTouchMore\": { \"120x120\": \"assert/favicon.ico\", \"180x180\": \"assert/favicon.ico\" } }, \"fontsettings\": { \"theme\": \"white\", \"family\": \"sans\", \"size\": 2 }, \"page-treeview\": { \"copyright\": \"Copyright © 1141134779@qq,com 2020\", \"minHeaderCount\": \"2\", \"minHeaderDeep\": \"2\" }, \"sharing\": { \"all\": [\"facebook\", \"google\", \"linkedin\", \"twitter\", \"weibo\", \"qq\"] }, \"donate\": { \"wechat\": \"/assert/wechat.jpg\", \"alipay\": \"/assert/alipay.jpg\", \"title\": \"\", \"button\": \"赏\", \"alipayText\": \"支付宝打赏\", \"wechatText\": \"微信打赏\" }, \"github\": { \"url\": \"https://github.com/BourbonWang\" } }, \"language\": \"zh-hans\", \"title\": \"Bourbon\", \"variables\": {}, \"styles\": { \"website\": \"/assert/styles/website.css\" } } webhook 实现服务器自动更新博客 由于需要频繁更新博客，不可能每次更新都重新上传服务器，所以需要服务器自动拉取gitbook文件夹。可以将gitbook上传到github，然后使用 webhook 将push与服务器关联。这样每次更新后push到github，然后webhook执行服务器的脚本，将文件夹 pull 下来，重启gitbook 服务。 docker 这里将博客放到docker里，方便管理，不会与其他服务冲突。 拉取 node 镜像，创建容器 docker run -itd --name blog -p 4000:4000 node:10.19 /bin/bash docker exec -it blog /bin/bash 容器内同样方法安装gitbook。 部署 webhook apt 换源(debian)后，安装 pip apt-get install python3-pip 我使用的 webhookit：https://github.com/hustcc/webhookit 可根据文档自行安装。 由于这个webhook只能用python2, 注意使用 pip2。 pip2 install webhookit webhookit_config > /home/webhook/config.py 编辑config.py ，只需要修改repo_name/branch_name 和 SCRIPT # -*- coding: utf-8 -*- ''' Created on Mar-03-17 15:14:34 @author: hustcc/webhookit ''' # This means: # When get a webhook request from `repo_name` on branch `branch_name`, # will exec SCRIPT on servers config in the array. WEBHOOKIT_CONFIGURE = { # a web hook request can trigger multiple servers. 'repo_name/branch_name': [{ # if exec shell on local server, keep empty. 'HOST': '', # will exec shell on which server. 'PORT': '', # ssh port, default is 22. 'USER': '', # linux user name 'PWD': '', # user password or private key. # The webhook shell script path. 'SCRIPT': '/home/webhook/shell.sh' }, ...], ... } 创建shell.sh，就是自动执行的脚本，用来拉取博客，完成更新 cd /home/blog git pull gitbook install gitbook init gitbook serve 启动 webhook webhookit -c /home/webhook/config.py -p 4001 监听4001端口，浏览器访问即可查看webhook URL以及配置信息。 配置 github 仓库 -> Settings -> Webhooks -> Add webhook payload URL：填写webhook URL Content type ：application/json 触发条件：Just the push event. Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-07 14:28:32 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"network/http.html":{"url":"network/http.html","title":"HTTP 和 HTTPS","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 HTTP 与 HTTPS HTTP 特点 基于请求和响应 无状态 无连接 简单快速、灵活 请求报文 请求行 请求头 请求体 响应报文 状态行 响应头 存在的问题 HTTPS 加密 数字摘要 数字签名 过程 不足 安全性 成本 HTTP 与 HTTPS HTTP HTTP是超文本传输协议的缩写，是一个基于请求与响应，无状态的，应用层的协议，常基于TCP/IP协议传输数据，互联网上应用最为广泛的一种网络协议，所有的WWW文件都必须遵守这个标准。设计HTTP的初衷是为了提供一种发布和接收HTML页面的方法。随着发展，HTTP可以支持传输任何类型的数据。 特点 基于请求和响应 HTTP协议一般用于B/S架构，浏览器向服务端发送请求报文，服务器解析后，将数据包含在响应报文中，发送给浏览器。 无状态 协议对事务处理没有记忆能力，后续处理如果需要之前的信息，则必须重传。比如访问一个网站需要反复进行登录操作。对于这个特点，现有的一些解决方案比如 利用 Cookie / Session HTTP/1.1持久连接（HTTP keep-alive）。只要任意一端没有明确提出断开连接，则保持TCP连接状态，在请求首部字段中的Connection: keep-alive即为表明使用了持久连接 这样可以让用户在登陆后一段时间内不需要再次登陆。 无连接 由于无状态特点，每次请求需要通过TCP三次握手四次挥手，和服务器重新建立连接。当一个用户与服务器进行频繁的请求时，建立TCP连接将耗费大量的开销。 为此，HTTP/1.1 支持了长连接，与同一个用户的多次数据传输可以使用同一个TCP信道。但对一个信道的多个请求存在排队，不支持同时处理多个HTTP连接。 HTTP/2.0在其上实现了多路复用，对于同时的多个请求，可以同时在信道上发送和接收，大幅缩短资源请求的耗时，在请求大数量资源时效果显著。 简单快速、灵活 客户向服务器请求服务时，只需传送请求方法和路径。HTTP允许传输任意类型的数据对象。传输的类型由Content-Type加以标记。 请求报文 一个HTTP请求报文由请求行（request line）、请求头（header）、空行和请求体4个部分组成。 请求行 请求行由三部分组成：请求方法，请求URL（不包括域名），HTTP协议版本。 请求方法有 GET：获得URI指定的资源，参数放在URL后面。传输过程中可能会被浏览器、网关等缓存，参数可以直接在地址栏看到，不适合用来传递敏感数据。一些浏览器或服务端对URL的长度有限制，不适合传递大量数据。浏览器中点击的URL都是GET请求。 POST: 请求参数放在请求体中，以key1=value1&key2=value2的形式存放，不会显示在URL中。POST请求不会被缓存，可以用来传递用户信息等敏感数据。请求体没有长度限制，所以可以传递大量数据。浏览器的表单提交、文件上传等都是POST。 HEAD：和GET相似，不过服务端接收到HEAD请求时只返回响应头，不发送响应体。使用HEAD不必传输整个资源内容，就可以得到资源的信息。所以，如果只需要查看某个页面的状态时，用HEAD更高效，因为省去了传输页面内容的时间。 PUT: 向服务器发送请求存储一个资源，并用URI作为标识。PUT和POST都是向服务器发送数据，但PUT通常指定了资源的存放位置，而POST则没有，POST的数据存放位置由服务器自己决定。 DELETE: 请求服务器删除URI指定的资源 OPTIONS: 用于获取当前URL所支持的方法。若请求成功，会在HTTP头中包含一个名为“Allow”的头，值是所支持的方法，如“GET, POST”。 TRACE: 请求服务器回送收到的请求信息，主要用于测试。 CONNECT: HTTP/1.1的方法，将连接转换为一个TCP/IP管道，通常用于SSL加密服务器的链接与非加密的HTTP代理服务器的通信。 请求头 User-Agent : 产生请求的浏览器类型 Accept : 希望接受的数据类型，比如 Accept：text/xml（application/json） Accept-Encoding: 浏览器表明自己接收的编码方法 Accept-Language: 浏览器接收的语言 Accept-Charset: 接收的字符集 Content-Length：请求体的长度 Content-Type：请求体的数据类型。比如 Content-Type：text/html（application/json） Referer：提供了该请求从哪个链接跳转而来 Connection：标明Connection: keep-alive则为长连接。请求结束后，建立的TCP连接不会关闭，当客户端再次请求相同的服务器时，将继续使用这个TCP连接。有保持时间限制。 Host: 请求的主机名，从URL中提取。 If-Modified-Since: 检查资源的修改时间，和响应头的Last-Modified一起。当请求同一个资源时，将上一次请求返回的Last-Modified填入If-Modified-Since中。服务器将这个时间与真实资源的修改时间对比。如果未过期，则返回304, 使用缓存的文件。如果过期，则返回200, 将新的资源返回给浏览器。 Cache-Control: 指定缓存机制。Public表示可以被任何缓存；Private表示只缓存到私有缓存中；no-cache表示不会被缓存。 Cookie：将cookie的值发给服务器。可以用来发送session id等。 请求体 在浏览器发送HTTP请求时，GET请求往往通过URL来发送，这时无法设置请求体，只有URL，请求数据只能放在URL的querystring中；POST请求往往来自表单提交或发送文件，POST仍然可以在URL上附带一些参数，只不过表单里的数据都放在请求体中。 实际使用HTTP作为接口时，无论GET还是POST都可以使用请求体。我们通常把所有的“控制类”信息应该放在请求头中，具体的数据放在请求体里。于是服务器端在解析时，总是会先完全解析全部的请求头部。这样服务器端总是希望能够了解请求的控制信息后，就能决定这个请求进一步如何处理，是拒绝，还是处理数据，或者直接转发。比如，收到一个请求，检查请求头看到Content-Length里的数太大，或者Content-Type自己不支持，或者Accept要求的格式无法处理，就可以直接返回失败，节省了读取请求体的带宽。 响应报文 响应报文与请求报文的结构相似，也是由状态行，响应头，空行，响应体组成。 状态行 状态行包含了HTTP版本，状态码，以及状态码的描述。 状态码由3位十进制数字组成。详细请看HTTP状态码 1xx（信息）：收到请求，需要继续执行操作 101：Continue, 客户端继续请求 2xx（成功）：请求已成功接收并处理 200：OK，请求成功 201：Created，已创建 202：Accepted, 已接受 3xx（重定向）：需要采取进一步措施才能完成请求 301：Moved Permanently，永久重定向。浏览器会记录新的URI，以后直接跳转到新的URI。 302：Found，临时重定向。以后浏览器仍然使用原有URI访问服务器，可用来流量统计等。 304：Not Modified，未修改。客户端通过If-Modified-Since检查资源时，如果资源未修改，服务器返回此状态码，不会返回任何资源，客户端使用本地的缓存。 4xx（客户端错误）：请求包含错误的语法或无法完成请求 400：Bad Request，客户端请求的语法错误，服务器无法理解 401：Unauthorized，要求用户身份验证 403：Forbidden，服务器理解请求，但是拒绝执行此请求 404：Not-Found，服务器无法根据客户端的请求找到资源。通过此代码，网站设计人员可设置\"您所请求的资源无法找到\"的个性页面 405：Method Not Allowed，客户端请求中的方法被禁止 5xx（服务器错误）：服务器在处理请求时发生错误 500：Internal Server Error，服务器内部错误，无法完成请求 501：Not Implemented，服务器不支持请求的功能，无法完成请求 502：Bad Gateway，作为网关或者代理工作的服务器尝试执行请求时，从远程服务器接收到了一个无效的响应 503：Service Unavailable，由于超载或系统维护，服务器暂时的无法处理客户端的请求。 504：Gateway Time-out，充当网关或代理的服务器，未及时从远端服务器获取请求 505：HTTP Version not supported，服务器不支持请求的HTTP协议的版本，无法完成处理 响应头 Content-Type: 响应体的数据类型 Content-Length: 响应体的长度 Content-Encoding: 响应体的编码和压缩方式 Content-Language: 响应体语言 Last-Modified: 指定资源的最后修改时间 Server: 服务器的软件信息 Connection: 和请求头的Connection相同 Location: 重定向的新地址 Date: 生成报文的具体时间 Expires: 告诉浏览器在指定过期时间内使用本地缓存 Set-Cookie: 发送cookie，用来把新创建的session id返回给客户端 存在的问题 请求信息明文传输，容易被窃听截取。 数据的完整性未校验，容易被篡改。 没有验证对方身份，存在冒充危险。 HTTPS 为了解决上述HTTP存在的问题，就用到了HTTPS。HTTPS是一种通过计算机网络进行安全通信的传输协议，经由HTTP进行通信，利用SSL/TLS建立全信道，加密数据包。HTTPS使用的主要目的是提供对网站服务器的身份认证，同时保护交换数据的隐私与完整性。 加密 发送方随机生成密钥对消息进行对称加密。使用接收方的公钥加密对称密钥，仅有接收方可以解密，从而得到对称密钥解出明文。任何中间人无法得到接收方的私钥，也就无法破解消息。 数字摘要 对消息进行哈希，得到固定长度的唯一的码，不同消息的哈希码不同，将此哈希码一同发送给接收方，用于消息验证。接收方用同样的哈希函数对收到的明文进行哈希，与收到的哈希码比较，从而可以判断消息是否完整或被更改。由于哈希函数本身保证了无法从哈希码反推出明文，因此可以保证数字摘要是可靠的。 数字签名 验证消息是否真实来自发送方，也可以认为是验证数字摘要是否真实来自发送方。发送方用发送方的私钥对数字摘要进行加密。这样仅能用发送方的公钥进行解密，中间人无法进行伪造。 过程 首先客户端通过URL访问服务端443端口请求建立SSL连接。包括加密协议，版本，随机数1等等 服务端选择合适的加密协议，产生随机数2, 返回客户端 服务端随即发送CA证书，其中包含了服务端的公钥。 客户端验证证书。生成一个随机数，即预主密钥。 客户端通过随机数1,随机数2,预主密钥组合成会话密钥。用服务端的公钥进行加密 服务端收到后用私钥解密，同样的方式组装出会话密钥。 服务端用会话密钥加密一条消息发送回客户端，用来验证是否得到了正确的会话密钥。 客户端同样用会话密钥加密一条消息，用来告诉服务端消息可以正常接收。 SSL连接建立完成。 不足 安全性 HTTPS协议的加密范围也比较有限，在黑客攻击、拒绝服务攻击、服务器劫持等方面几乎起不到什么作用 SSL证书的信用链体系并不安全，特别是在某些国家可以控制CA根证书的情况下，中间人攻击一样可行 成本 SSL证书需要购买，功能越强大的证书费用越高 HTTPS协议多次握手，会使页面的加载时间延长近50%，增加耗电。比较好的方式是采用分而治之，网站主页使用HTTP协议，有关于用户信息等方面使用HTTPS。 HTTPS连接缓存不如HTTP高效，流量成本高。 SSL涉及到的安全算法会消耗 CPU 资源，对服务器资源消耗较大。 Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-17 08:41:04 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"network/tcp.html":{"url":"network/tcp.html","title":"TCP详解","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 TCP 详解 特点 报文 可靠数据传输 确认应答机制 滑动窗口 超时重传 快速重传 建立和结束连接 流量控制 延迟应答 拥塞控制 加性增，乘性减（AIMD） 慢启动 TCP 详解 TCP是运输层的可靠运输协议。HTTP，HTTPS，SSH，Telnet，FTP等应用层协议都是基于TCP。 特点 TCP是面向连接的。因为在一个进程可以开始向另一个进程发送数据之前，这两个进程必须先握手，即必须相互发送一些特殊的报文，以确定数据传输所需的参数。 TCP提供全双工服务。如果进程A与进程B存在TCP连接，那么应用层数据就可以在两个进程间双向流通。 TCP连接是点对点的。即单个发送方与单个接收方间的连接。TCP用（源IP地址，源端口号，目的IP地址，目的端口号）四元组来唯一标识进程。 TCP是面向字节流的。对于每个连接，TCP会建立发送缓冲区和接收缓冲区。上层应用会将数据放入缓冲区，TCP会按MSS（最大报文段长）分割成一个个报文，在合适时机发送出去。接收数据的时候，应用也是从缓冲区读取数据。因此TCP的读与写不需要完全匹配。 TCP通过报文段检验和，确认应答，超时重传，流量控制，拥塞控制等机制提供可靠传输。 报文 32位序号: 序号是该报文段首字节的编号。 32位确认号：TCP是全双工的，在发送数据的同时也在接收对方的数据。主机A填充进报文段的确认号是主机A期望从B收到的下一字节的序号。序号和确认号是保证TCP可靠传输的关键。 4位首部长度：从首部到数据部分的偏移量，一般TCP首部长度为20字节 6位标志位 URG: 标识紧急指针是否有效 ACK: 标识确认序号是否有效 PSH: 用来提示接收端应用程序立刻将数据从tcp缓冲区读走 RST: 要求重新建立连接. 我们把含有RST标识的报文称为复位报文段 SYN: 请求建立连接. 我们把含有SYN标识的报文称为同步报文段 FIN: 通知对端, 本端即将关闭. 我们把含有FIN标识的报文称为结束报文段 16位窗口：用于流量控制，指示接收方愿意接收的字节数量 16位检验和：校验和不光包含TCP首部, 也包含TCP数据部分 可靠数据传输 确认应答机制 TCP使用序号和确认号实现可靠传输。当A向B发送数据时，携带序号Seq Num为该报文段的首字节的编号；确认号Ack Num为期望对方下次发送报文的首字节编号，同时也告诉对方Ack Num之前的数据都已接收。从直观上，发送的每个报文都应当得到一个专门的ACK回应。实际上，双方往往是在互相发送各自的数据，然后各自回应对方。因此可以在发送自己的数据的时候，顺便带上回应对方的ACK。 滑动窗口 窗口大小指的是无需等待确认应答就可以继续发送数据的最大值. 发送方将维护一个滑动窗口。窗口内的报文不需要等待ACK应答，直接发送。 对于接收方：如果一个序号n的分组被正确的接收，且按序（即上次交付给上层的是序号n-1的分组），则为序号n的分组回应ACK，然后交付给上层。对于正确但无序的分组，TCP对将其暂时缓存，应答ACK仍为最近按序正确接收的分组序号。 因此，如果发送方收到分组k的应答ACK，说明k和k之前的分组都已成功接收。发送方可以将被确认过的数据从缓冲区删掉，窗口向前移动，继续发送其他的报文。 超时重传 发送的数据报文或应答的ACK报文可能在网络中丢失。当发送报文一段时间后仍未收到确认ACK，TCP将重新发送该报文，然后重置定时器。 对于连续发送的报文，如果第一个报文触发了超时重传，而在新的超时时间之前收到了第二个报文ACK，第二个报文将不会重传。 快速重传 超时重传的问题是超时周期可能较长。当一个分组丢失时，发送方可能要等待很久才重传分组，从而增加端到端的时延。事实上，发送方往往一次发送大量的分组，当有分组丢失时，会引起大量相同的冗余ACK。如果TCP发送方收到了超过3个冗余的ACK，它就认为这之后的分组发生丢失，TCP将进行快速重传。 建立和结束连接 TCP采用三次握手来创建连接，四次挥手来断开连接。详细请见另一篇文章: TCP三次握手和四次挥手 流量控制 前面说到，双方都为该连接设置了接收缓存。当接收到正确的报文后，它就将数据放入缓存。上层的应用进程会从缓存中读取数据，但没必要数据刚到达就读取，应用进程甚至可能过很长时间后才读取。如果数据读取十分缓慢，而发送方发送的数据太多太快，会导致接收缓存溢出。 为此，TCP提供了流量控制。流量控制是保证了发送速率和接收方的读速率相匹配。接收方将剩余缓存大小填入TCP报头的“窗口”字段，用于告诉发送方，自己还有多少缓存空间。窗口越大，说明接收方的吞吐量越高。由于TCP是全双工的，双方都各自维护一个接收窗口。 当接收方的缓冲区快满了，会将更小的窗口通知发送方，发送方会减慢自己的发送速度。当窗口为0时，发送方不再发送数据，但会定期的发送只有一个字节的报文段，用于探测接收方的窗口。 延迟应答 如果接收数据后立即进行ACK应答，这时返回的窗口可能比较小。实际上，接收方的处理数据速度可能很快，稍等一段时间就可以得到更大的缓冲区，返回更大的窗口。窗口越大, 网络吞吐量就越大, 传输效率就越高。TCP的目标是在保证网络不拥堵的情况下尽量提高传输效率。但延迟应答也有限制： 数量限制: 每隔N个包就应答一次 时间限制: 超过最大延迟时间就应答一次 拥塞控制 数据的丢失一般是在网络拥塞时由于路由器缓存溢出引起的。因此，分组重传是网络拥塞的征兆，但不能解决网络拥塞问题。TCP需要另一些机制在面临网络拥塞时遏制发送方。TCP拥塞控制的基本思想是，当出现丢包事件（收到3个冗余ACK）时，让发送方通过减小拥塞窗口的大小来降低发送速率。TCP的拥塞控制算法包括：1. 加性增，乘性减（AIMD）; 2. 慢启动 加性增，乘性减（AIMD） 每发生一次丢包事件，发送方就将当前的窗口大小减半。但不能降到低于一个MSS（最大报文段长）。 当收到前面数据的ACK时，就可以认为当前网络没有拥塞，可以考虑增加发送速率。这种情况下，TCP每次收到一个ACK确认后就把窗口增加，每个往返时延内拥塞窗口增加1个MSS。 总而言之，TCP感受到网络无拥塞就加性的增加发送速率，感受到网络拥塞时就乘性的减小发送速率。因而称为加性增，乘性减（Additive-Increase，Multiplicative-Decrease）算法。 慢启动 在TCP连接刚开始时，初始的拥塞窗口被设为1个MSS，而实际可用的带宽往往比这大很多。仅仅线性的增加发送速率，可能要很长时间才能达到最大的速率。因此，TCP发送方在初始阶段并不是线性的增加发送速率，而是指数级的。直到发生第一个丢包事件（或到达阈值），窗口大小减为一半，然后才会加性增。这个指数级的增加发送速率的过程称为慢启动。 每当一个报文被确认后，窗口都增加1个MSS，从而使发送速率指数增长。比如：初始时只有1个MSS，发送一个报文。收到确认后，窗口增加1个MSS，然后就可以发出两个报文。这两个报文被确认后，窗口扩大到了4个MSS。因此在慢启动阶段，每过一个RTT，窗口都增加一倍。 为了方便窗口减半和控制慢启动的窗口上限，发送方记录了窗口的阈值。初始时设定为一个较大的值。慢启动阶段达到阈值后将开始加性增。然后每次增加窗口时，阈值都会随之增加。当出现丢包或超时事件时，阈值减半，即新的窗口大小。 事实上，TCP对超时事件的反应与丢包事件（收到3个冗余ACK）有所不同。当出现超时事件，TCP将阈值减半，然后将窗口直接减为1个MSS，然后重新开始慢启动阶段，直到达到减半后的阈值。TCP对丢包事件与超时事件采取不同策略是因为，当收到3个冗余ACK，仅代表一些报文丢失，而其他一些报文能够收到，TCP会尽可能的试探网络上能利用的带宽。 Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-22 10:10:10 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"network/three-way-handshake.html":{"url":"network/three-way-handshake.html","title":"TCP三次握手和四次挥手","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 TCP三次握手和四次挥手 三次握手 过程 第一次握手 第二次握手 第三次握手 原因 四次挥手 第一次挥手 第二次挥手 第四次挥手 常见问题 TCP三次握手和四次挥手 三次握手 过程 第一次握手 建立连接时，客户端发送SYN报文，标志位SYN=1。 随机生成初始序列号ISN，作为序列号Seq Num = client_isn。ISN动态随机生成使得每个tcp session的字节序列号没有重叠。也为了增加安全性，为了避免被第三方猜测，从而被第三方伪造的RST报文Reset。伪造的报文要想成功，需要Seq Num 位于对方的合法接收窗口内， 而由于ISN是动态随机的，猜出对方接收窗口难度加大。 规定第一次握手不携带数据。如果第一次握手携带数据，先由服务端缓存下来等建立连接后再处理，这样会导致SYN FLOOD攻击。攻击者会用大量的携带数据的握手报文，让接收方被迫开辟大量的空间来缓存这些数据，从而耗尽内存，关闭服务。 客户端进入SYN_SENT状态，等待服务器确认。 第二次握手 服务器收到SYN报文后，如果同意连接，则发出确认报文。告知客户端：客户端发送正常，服务端接收正常。 确认报文中的标志位 ACK=1, SYN=1, 确认序号Ack Num = client_isn + 1, 同时也要为自己初始化一个序列号 Seq Num= server_isn。这个报文也不能携带数据, 但是同样要消耗一个序号。 TCP服务器进程进入了SYN-RCVD状态。 第三次握手 客户端收到确认报文后，再次向服务器确认，告知服务器：客户端接收正常，服务器发送正常。 确认报文的标志位ACK=1，序列号Seq Num = client_isn + 1, 确认序号Ack Num = server_isn + 1， 第三次握手时可以携带数据。因为伪造的第三方是无法接收到第二次握手的报文，能发出第三次握手报文的用户都是合法的。 TCP连接建立，客户端进入ESTABLISHED状态。当服务器收到客户端的确认后也进入ESTABLISHED状态，就可以正常处理携带的数据。此后双方就可以开始通信了。 原因 从建立连接的过程可以知道，三次握手是可以让双方确认彼此收发能力的最小次数。除此之外，三次握手还有其他原因： 阻止重复历史连接的初始化 The principle reason for the three-way handshake is to prevent old duplicate connection initiations from causing confusion. RFC 793指出，三次握手的主要原因是防止旧的重复连接初始化造成混乱。 比如客户端发送一个Seq Num = 50的SYN报文1，由于网络阻塞，客户端又重新发送发送了一个Seq Num = 100的SYN报文2。一段时间后，服务器先收到了SYN报文1，并且返回Ack Num = 51的确认报文。客户端收到后，检查发现这个报文并不是自己期望的Ack Num = 101的报文，所以发送了RST报文来终止连接。一段时间后，服务器收到了SYN报文2，返回确认报文Ack Num = 101。客户端收到后再次确认，建立连接成功。 所以在上面这个过程中，第三次握手让客户端可以判断当前连接是否是旧的重复连接，从而选择终止连接或成功建立连接。 如果是两次握手，客户端就不能判断是否是重复连接。因为第二次握手时，服务器已经为连接分配资源，客户端只能选择建立连接, 而这个连接是没有任何用处的。这样会导致双方资源的浪费。 同步双方初始序列号 TCP通过序列号维持可靠传输。通过序列号：接收方可以丢弃重复的包；接收方可以根据序号按序接收；可以标识发出的包中，有哪些被对方成功接收。客户端发送携带初始序列号的SYN报文，需要服务端返回ACK应答，表示客户端的初始序列号成功创建滑动窗口。反之，服务端的初始序列号同样需要客户端的确认。这样的两次来回，才能确认双方的初始序列号都可以同步。在这来回的四次中，服务端确认ACK，和服务端发送自己的初始序列号可以合并在一个报文中，因此就简化成了三次握手。 避免资源浪费 如果只有两次握手，当客户端的SYN报文在网络中阻塞时，客户端没有收到来自服务器的ACK报文，就会重新发送SYN。一段时间后，当服务器接收到了SYN报文，由于没有第三次握手，服务器不清楚客户端是否收到了自己的确认报文，所以只能对每个SYN都建立一个连接。这样会导致服务器建立多个重复冗余的连接，造成资源浪费。 四次挥手 过程 第一次挥手 客户端发送FIN报文，标志位FIN=1，序列号为Seq Num为之前对方最后传过来的数据的最后一个字节的序号+1，假设Seq Num = u. 客户端停止发送数据，进入FIN-WAIT-1状态。 第二次挥手 服务端收到FIN报文后，发出确认报文，标志位ACK=1，确认序号Ack Num = u + 1，假设自己的序列号Seq Num = v。 服务端进入CLOSE-WAIT状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态。即客户端已经没有数据要发送了，但是服务器若发送数据，或者有数据包还在网络中，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。 客户端收到服务器的确认请求后，进入FIN-WAIT-2状态，等待服务器发送FIN报文，期间继续接收服务器发送的数据包。 第三次挥手 一段时间后，服务器发送完最后的数据包，就向客户端发送FIN报文，标志位FIN=1, Ack Num = u+1, 由于CLOSE-WAIT状态可能又发送了一些数据，假设此时Seq Num = w。服务器进入LAST-ACK状态，等待客户端最后的确认。 第四次挥手 客户端收到FIN报文后，发出确认报文，标志位ACK=1，Ack Num = w+1，Seq Num = u + 1. 客户端进入TIME-WAIT状态。TCP连接并未立即释放，需要等待 2*MSL的时间，然后释放资源，进入CLOSED状态。 服务端收到确认报文后，立即进入CLOSED状态。释放资源。因此服务端结束连接的时间比客户端稍早一些。 常见问题 为什么要挥手四次？ 每个方向都需要一个FIN和ACK，所以需要四次。在三次握手中，服务端的确认ACK和建立连接SYN合并在一个报文。但在四次挥手中，由于客户端发送FIN仅代表不再发送数据，但是还能接收数据；服务端对FIN进行回应后，可能还有数据需要发送，需要等全部发完后才能发送FIN报文来表示服务端同意关闭连接。因此，服务器确认ACK和发送FIN需要分开发送，从而比三次握手多了一次。 为什么TIME_WAIT状态等待2 * MSL 的时间？ MSL是报文最大生存时间，超过这个时间报文将被丢弃。如果服务端没有收到最后来自客户端的ACK报文，超时后服务端会重新发送FIN报文。客户端收到FIN后，会重新发送ACK报文给服务端。双方一去一回的时间为2MSL。这样，客户端可以在2 MSL 的时间内收到重传的FIN报文，然后发出ACK，重置2 MSL的计时器。超过2 MSL后，则说明不再有服务端重传的FIN报文，最后的ACK报文已被服务端接收，可以关闭连接了。 需要TIME_WAIT状态的原因 保证连接正确关闭 TIME-WAIT - represents waiting for enough time to pass to be sure the remote TCP received the acknowledgment of its connection termination request. RFC 793指出，TIME_WAIT的作用是等待足够的时间来确保服务端接收到最后的ACK。 如果没有TIME_WAIT状态，当客户端最后发送的ACK报文在网络中丢失，而客户端直接进入CLOSED状态。服务端将永远无法收到最后的ACK，那么服务端则会一直处在LAST_ACK状态。 当客户端想再次建立连接，发送SYN报文后，服务端由于一直处在LAST_ACK状态，会发送RST报文给客户端，连接建立的过程就会被终止。 上面说过，将等待时间设置为2 * MSL可以保证服务端能够正常收到最后的ACK报文。 防止新的连接收到旧连接的数据包 如果没有TIME_WAIT状态，当在关闭连接之前发送的数据包1在网络中延迟，然后连接正常被关闭。这时如果双方有相同端口的新的TCP连接建立，而恰好来自旧的连接的数据包1抵达，那么就有可能将这个来自旧连接的数据包接收，从而造成错乱。 将TIME_WAIT设置成2 * MSL，保证了两个方向的数据包都已经超时丢弃，使得旧连接的数据包在网络中自然消失，从而避免了新的连接收到旧连接的数据包的情况。 TIME_WAIT状态等待时间过长有什么危害 内存占用。TCP连接的资源迟迟无法释放。如果是服务器（服务器主动发起的断开请求），可能会导致线程池占满，处理不过来新的连接。 端口占用。一个TCP连接至少消耗一个本地端口。当处在TIME_WAIT状态的连接过多，占满了端口，将导致无法创建新的连接。 如果已经建立了连接, 但是客户端突发故障了怎么办? TCP设有一个保活计时器，客户端如果出现故障，服务器不能一直等下去浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若2小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75分钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。 Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-22 10:10:10 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"network/udp.html":{"url":"network/udp.html","title":"UDP详解","keywords":"","body":"UDP 详解 sdkjfhdskjfhdslkjfhsdlkjfghsdkf Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-23 15:42:06 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"other/reverseproxy.html":{"url":"other/reverseproxy.html","title":"Docker 安装 Nginx 并实现反向代理","keywords":"","body":"TreeviewCopyright © 1141134779@qq,com 2020 all right reserved, powered by aleen42 Docker 安装 Nginx 并实现反向代理 安装 Nginx 镜像 拉取镜像 创建实例 创建关键目录映射点 反向代理 Docker 安装 Nginx 并实现反向代理 安装 Nginx 镜像 拉取镜像 docker pull nginx 查看镜像 docker images 创建实例 docker run --name nginx-test -p 80:80 -d nginx docker start nginx-test 浏览器访问服务器ip，运行nginx欢迎页面 创建关键目录映射点 本地创建文件夹 html: nginx存储网页的目录 logs：日志目录 conf：配置文件目录 mkdir -p nginx/html nginx/logs nginx/conf 将刚才创建的nginx容器的配置文件拷贝到本地 docker cp nginx-test:/etc/nginx ~/nginx/conf 创建新的nginx容器 docker run -d -p 80:80 --name nginx -v ~/nginx/html:/usr/share/nginx/html -v ~/nginx/logs:/var/log/nginx -v ~/nginx/conf:/etc/nginx nginx docker start nginx 反向代理 反向代理就是将访问本机的数据代理转发到本机的其他端口。比如，一个网站在4000端口上，而浏览器默认访问而的是80端口。就可以用nginx将访问80端口的数据转发到4000端口上，然后浏览器直接访问80端口就可以看到网站了。 所以要先知道要反向代理的服务的地址。由于我们要代理的是容器，先查看容器的ip docker inspect 容器名 在最后的Networks下看到IPAddress 编辑conf/conf.d/default.conf，修改proxy_pass 为目标容器的ip和端口号 location / { #root /usr/share/nginx/html; #index index.html index.htm; proxy_pass http://172.17.0.2:4000; } 访问浏览器，成功跳转到目标网页 Copyright © 1141134779@qq.com 2020 all right reserved，powered by GitbookFile Modify: 2021-01-23 15:24:35 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"}}